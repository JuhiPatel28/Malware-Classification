# -*- coding: utf-8 -*-
"""Preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lOGFGf-WPIRMUIHOpYk3pBtV6ci5Nevi

## Importing necessary libraries
"""

import pandas as pd
import numpy as np

#creating a dataframe to read the dataset after mounting in google drive
raw_csv_data = pd.read_csv("extracted_attributes-consolidated.csv")

raw_csv_data.info()

#eye balling the data
raw_csv_data.head(5)

"""## Formatting "Library" column"""

raw_csv_data['Library'] =raw_csv_data['Library'].astype(str).str.replace("[","").str.replace("]","")
raw_csv_data['Library']=raw_csv_data['Library'].str.replace('\s*,\s*',',')

raw_csv_data['Library'] = raw_csv_data['Library'].str.upper()

raw_csv_data.head(3)

"""Creating dummy variable for "Library""""

#copying the old dataframe with a new dataframe meanwhile to mess around
df = raw_csv_data.copy()
encoded_library=df['Library'].str.get_dummies(sep=',')
df=pd.concat([df,encoded_library], axis=1)
pd.options.display.max_columns = None
pd.options.display.max_rows = None
display(df.head(10))

"""# **Observation 1:**

Created new columns with unique libraries and passing boolean representation if a library call was done for a particular resource

## Formatting "Language" column
"""

df['Language'] = df['Language'].astype(str).str.replace("[","").str.replace("]","")
df['Language'] = df['Language'].str.replace('\s*,\s*',',')

df['Language'] = df['Language'].str.upper()

df.head(3)

"""Creating dummy variable for "Language""""

#copying the old dataframe with a new dataframe meanwhile to mess around
df2 = df.copy()
encoded_library2=df2['Language'].str.get_dummies(sep=',')
df2=pd.concat([df2,encoded_library2], axis=1)
pd.options.display.max_columns = None
pd.options.display.max_rows = None
display(df2.head(10))

"""# **Observation 2:**

Created new columns with unique languages and passing boolean representation if a certain language was used for a particular resource

## Unique Library calls made and Langauage used
"""

preprocessed_data = df2.copy()

preprocessed_data.head(3)

preprocessed_data = preprocessed_data.drop('Language', 1)
preprocessed_data = preprocessed_data.drop('Library', 1)

preprocessed_data = preprocessed_data.rename(columns={"APTGroup": "APT Group"})

preprocessed_data.head(3)

from sklearn.preprocessing import LabelEncoder

preprocessed_data['APTGroup'] = LabelEncoder().fit_transform(preprocessed_data['APT Group'])
preprocessed_data['APTGroup'].max()
preprocessed_data.head(5)

#preprocessed_data.dropna(axis=0, how='any', inplace=True)
preprocessed_data.isnull().sum()
#preprocessed_data.info()

#preprocessed_data.tail(5)

preprocessed_data.to_csv('final_preprocessed_dataset.csv', index=True)

# Commented out IPython magic to ensure Python compatibility.
# %ls

